# Deep Average Network

## Как сделать домашку
- Сделайте закрытый репозиторий
  - Используйте этот репозиторий как template, воспользуйтесь [инструкцией](https://docs.github.com/en/repositories/creating-and-managing-repositories/creating-a-repository-from-a-template)
  - Добавьте в репозиторий [команду курса](https://github.com/BobaZooba/DeepNLP#%D0%BA%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4%D0%B0-%D0%BA%D1%83%D1%80%D1%81%D0%B0)
    - [Инструкция как добавлять](https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-personal-account-on-github/managing-access-to-your-personal-repositories/inviting-collaborators-to-a-personal-repository)
- Установите зависимости с помощью команды ```pip install -r requirements.txt```
- Сделайте задание
- Отправьте ссылку на репозиторий преподователю [@BobaZooba](https://github.com/BobaZooba)

## Описание задания
В этой домашке мы будет классифицировать твиты на 3 тональности.  
Вы будете использовать предобученные эмбеддинги слов, так что для начала обязательно нужно посмотреть [туториал по их использованию](https://github.com/BobaZooba/DeepNLP/blob/master/Tutorials/Word%20vectors%20%26%20Data%20Loading.ipynb).

Вам предстоит реализовать такую модель:
![Архитектура модели DAN](https://www.researchgate.net/profile/Shervin-Minaee/publication/340523298/figure/fig1/AS:878252264550411@1586403065555/The-architecture-of-the-Deep-Average-Network-DAN-10.ppm)

Что она из себя представляет:
- Мы подаем в нее индексы слов
- Переводим индексы слов в эмбеддинги
- Усредняем эмбеддинги
- Пропускаем усредненные эмбеддинги через `Multilayer Perceptron`

В этой домашке вам предстоит:
- Реализовать модель
- Обучить ее
- Понять хорошо ли вы это сделали

Это очень важная модель, потому что она очень простая и показывает достаточно высокие метрики. В дальнейшем на работе советую использовать такую модель как бейзлайн. И в качестве эмбеддингов слов взять эмбеддинги от берта/роберты/тд.

Используйте слои: `nn.Linear`, `nn.BatchNorm`, `nn.Dropout` и тд.

### Что нужно сделать в домашке с точки зрения архитектуры сети:
- Реализовать skip-connection (residual connection) в линейном слое
- Написать свой слой, в котором будут (порядок слоев ниже напутан, так что сами подумайте в каком порядке стоит расположить эти слои) :
  - `Dropout`
  - `BatchNorm` / `LayerNorm`
  - `Residual`, если вы не меняете размерность векторов
  - Функция активации
  - Линейный слой

### Опциональные задания:
- Использовать токенизатор и слой эмбеддингов от предобученного трансформера из библиотеки `transformers`
- Сделать усреднение эмбеддингов с учетом падов
  - Мы используем пады, чтобы сделать единую длину последовательностей в батче
    - То есть у нас максимальная длина в батче, например, 16 токенов, поэтому ко всем последовательностям, у которых длина ниже мы добавляем `16 - len(sequence)` падов
  - То есть получается так, что усредненный вектор предложения зависит от максимальный длины в батче, потому что
    - Среднее вектора `[1, 2, 3]` будет `2`. Среднее вектора `[1, 2, 3, 0, 0]` будет `1.2`
    - Получается, что усредняя с падами мы получаем "неправильный" вектор
  - То есть наши предсказания будут зависеть от того сколько падов у нас есть в предложении
  - Когда мы будем использовать нашу сетку в реальном процессе, скорее всего, мы будем подавать в нее по одному примеру, где падов не будет
    - То есть получается мы будем использовать нашу модель не в той же среде, как и обучали
      - Потому что наши входы меняются, мы не используем пады, результат усреднения другой
    - Это называется `distribution shift`, то есть когда мы учимся на одних данных, а используем на других
      - Это не всегда плохо, потому что иногда только так мы и можем учиться, например, когда мало данных нужного домена
      - Это плохо тогда, когда мы вносим это "случайно", например, как с неправильным усреднением, то есть это своебразный баг

## Оценивание
Будет проверяться корректность логики обучения, 
будут даваться комментарии что нужно исправить, 
если домашка будет сдана вовремя. 
Максимальный балл: 10.

## Дедлайн
03/10/2021  
Далее максимальный балл за работу: 7

## Важные просьбы
- Не отправляйте ссылку на `colab`
- Прежде чем отправить задание на проверку, очистите свой код от неиспользоваемого кода и неважных комментариев
